{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2eae283d-da0c-40e7-995f-8bb2078b9705",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c3146fa5-8829-4aae-a96f-2ba5e80c200c/lib/python3.12/site-packages (0.0)\nRequirement already satisfied: imbalanced-learn in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c3146fa5-8829-4aae-a96f-2ba5e80c200c/lib/python3.12/site-packages (from imblearn) (0.14.0)\nRequirement already satisfied: numpy<3,>=1.25.2 in /databricks/python3/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (2.1.3)\nRequirement already satisfied: scipy<2,>=1.11.4 in /databricks/python3/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.15.1)\nRequirement already satisfied: scikit-learn<2,>=1.4.2 in /databricks/python3/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.6.1)\nRequirement already satisfied: joblib<2,>=1.2.0 in /databricks/python3/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.4.2)\nRequirement already satisfied: threadpoolctl<4,>=2.0.0 in /databricks/python3/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (3.5.0)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "497ffb0f-a70f-4d19-92a7-7c2ee4d2fe80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1b35269-f139-4c35-98ba-2bb4ef5bd3cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Gold rows: 264 cols: 80\nSLA metrics: {'sla_accuracy': 0.8269230769230769, 'sla_precision': 1.0, 'sla_recall': 0.7954545454545454, 'sla_f1': 0.8860759493670886, 'sla_auc': 0.9218749999999999, 'sla_threshold': 0.55}\nREG metrics: {'reg_mae': 0.32346153846153847, 'reg_rmse': 1.2873564146970093, 'reg_r2': 0.9931832935807727}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\n2025/12/19 14:43:44 INFO mlflow.pyfunc: Validating input example against model signature\nRegistered model 'abc.abc_dw_gold.abc_dw_gd_model_Procurement_sla_Combined_Model_BAN6800' already exists. Creating a new version of this model...\nCreated version '7' of model 'abc.abc_dw_gold.abc_dw_gd_model_procurement_sla_combined_model_ban6800'.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ UC Model registered: abc.abc_dw_gold.abc_dw_gd_model_Procurement_sla_Combined_Model_BAN6800 v7\n✅ Predictions written to: abc.abc_dw_gold.abc_dw_gl_pr_po_kpi_predictions\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>pr_purchaserequisition</th><th>pr_itemnumber</th><th>purchaseorder</th><th>po_itemnumber</th><th>pr_companycode</th><th>po_companycode</th><th>pr_plant</th><th>po_plant</th><th>pr_documenttype</th><th>po_purchasingdoctypedesc</th><th>po_countrykey</th><th>record_type</th><th>pred_sla_breach_probability</th><th>pred_sla_breach_bin</th><th>pred_sla_breach_label</th><th>pred_pr_to_po_ageing</th><th>scoring_timestamp</th></tr></thead><tbody><tr><td>2000126351</td><td>00480</td><td>4500229324</td><td>00480</td><td>9900</td><td>9900</td><td>9900</td><td>9900</td><td>ZNPR</td><td>Local PO</td><td>GH</td><td>PR_PO_MATCHED</td><td>0.9826907011809315</td><td>1</td><td>YES</td><td>41.0</td><td>2025-12-19T14:43:51.956Z</td></tr><tr><td>2000130460</td><td>00050</td><td>4500230817</td><td>00050</td><td>9900</td><td>9900</td><td>9900</td><td>9900</td><td>ZNPR</td><td>Local PO</td><td>GH</td><td>PR_PO_MATCHED</td><td>0.32494237041334567</td><td>0</td><td>NO</td><td>24.0</td><td>2025-12-19T14:43:51.956Z</td></tr><tr><td>2000126540</td><td>00010</td><td>4500223373</td><td>00010</td><td>9900</td><td>9900</td><td>9900</td><td>9900</td><td>ZNPR</td><td>Local PO</td><td>GH</td><td>PR_PO_MATCHED</td><td>0.42864690499593183</td><td>0</td><td>NO</td><td>20.0</td><td>2025-12-19T14:43:51.956Z</td></tr><tr><td>2000126351</td><td>00180</td><td>4500229324</td><td>00180</td><td>9900</td><td>9900</td><td>9900</td><td>9900</td><td>ZNPR</td><td>Local PO</td><td>GH</td><td>PR_PO_MATCHED</td><td>0.9395665085827828</td><td>1</td><td>YES</td><td>41.0</td><td>2025-12-19T14:43:51.956Z</td></tr><tr><td>2000137276</td><td>00130</td><td>4500234397</td><td>00130</td><td>9900</td><td>9900</td><td>9900</td><td>9900</td><td>ZNPR</td><td>Local PO</td><td>GH</td><td>PR_PO_MATCHED</td><td>0.19873059422359807</td><td>0</td><td>NO</td><td>1.0</td><td>2025-12-19T14:43:51.956Z</td></tr><tr><td>2000126351</td><td>00120</td><td>4500229324</td><td>00120</td><td>9900</td><td>9900</td><td>9900</td><td>9900</td><td>ZNPR</td><td>Local PO</td><td>GH</td><td>PR_PO_MATCHED</td><td>0.9856629234031538</td><td>1</td><td>YES</td><td>41.0</td><td>2025-12-19T14:43:51.956Z</td></tr><tr><td>2000130460</td><td>00020</td><td>4500230817</td><td>00020</td><td>9900</td><td>9900</td><td>9900</td><td>9900</td><td>ZNPR</td><td>Local PO</td><td>GH</td><td>PR_PO_MATCHED</td><td>0.31767662290880677</td><td>0</td><td>NO</td><td>24.0</td><td>2025-12-19T14:43:51.956Z</td></tr><tr><td>2000126351</td><td>00080</td><td>4500229324</td><td>00080</td><td>9900</td><td>9900</td><td>9900</td><td>9900</td><td>ZNPR</td><td>Local PO</td><td>GH</td><td>PR_PO_MATCHED</td><td>0.9860368550270854</td><td>1</td><td>YES</td><td>41.0</td><td>2025-12-19T14:43:51.956Z</td></tr><tr><td>2000137276</td><td>00020</td><td>4500234397</td><td>00020</td><td>9900</td><td>9900</td><td>9900</td><td>9900</td><td>ZNPR</td><td>Local PO</td><td>GH</td><td>PR_PO_MATCHED</td><td>0.32579640768042645</td><td>0</td><td>NO</td><td>1.0</td><td>2025-12-19T14:43:51.956Z</td></tr><tr><td>2000126351</td><td>00240</td><td>4500229324</td><td>00240</td><td>9900</td><td>9900</td><td>9900</td><td>9900</td><td>ZNPR</td><td>Local PO</td><td>GH</td><td>PR_PO_MATCHED</td><td>0.9860368550270854</td><td>1</td><td>YES</td><td>41.0</td><td>2025-12-19T14:43:51.956Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2000126351",
         "00480",
         "4500229324",
         "00480",
         "9900",
         "9900",
         "9900",
         "9900",
         "ZNPR",
         "Local PO",
         "GH",
         "PR_PO_MATCHED",
         0.9826907011809315,
         1,
         "YES",
         41.0,
         "2025-12-19T14:43:51.956Z"
        ],
        [
         "2000130460",
         "00050",
         "4500230817",
         "00050",
         "9900",
         "9900",
         "9900",
         "9900",
         "ZNPR",
         "Local PO",
         "GH",
         "PR_PO_MATCHED",
         0.32494237041334567,
         0,
         "NO",
         24.0,
         "2025-12-19T14:43:51.956Z"
        ],
        [
         "2000126540",
         "00010",
         "4500223373",
         "00010",
         "9900",
         "9900",
         "9900",
         "9900",
         "ZNPR",
         "Local PO",
         "GH",
         "PR_PO_MATCHED",
         0.42864690499593183,
         0,
         "NO",
         20.0,
         "2025-12-19T14:43:51.956Z"
        ],
        [
         "2000126351",
         "00180",
         "4500229324",
         "00180",
         "9900",
         "9900",
         "9900",
         "9900",
         "ZNPR",
         "Local PO",
         "GH",
         "PR_PO_MATCHED",
         0.9395665085827828,
         1,
         "YES",
         41.0,
         "2025-12-19T14:43:51.956Z"
        ],
        [
         "2000137276",
         "00130",
         "4500234397",
         "00130",
         "9900",
         "9900",
         "9900",
         "9900",
         "ZNPR",
         "Local PO",
         "GH",
         "PR_PO_MATCHED",
         0.19873059422359807,
         0,
         "NO",
         1.0,
         "2025-12-19T14:43:51.956Z"
        ],
        [
         "2000126351",
         "00120",
         "4500229324",
         "00120",
         "9900",
         "9900",
         "9900",
         "9900",
         "ZNPR",
         "Local PO",
         "GH",
         "PR_PO_MATCHED",
         0.9856629234031538,
         1,
         "YES",
         41.0,
         "2025-12-19T14:43:51.956Z"
        ],
        [
         "2000130460",
         "00020",
         "4500230817",
         "00020",
         "9900",
         "9900",
         "9900",
         "9900",
         "ZNPR",
         "Local PO",
         "GH",
         "PR_PO_MATCHED",
         0.31767662290880677,
         0,
         "NO",
         24.0,
         "2025-12-19T14:43:51.956Z"
        ],
        [
         "2000126351",
         "00080",
         "4500229324",
         "00080",
         "9900",
         "9900",
         "9900",
         "9900",
         "ZNPR",
         "Local PO",
         "GH",
         "PR_PO_MATCHED",
         0.9860368550270854,
         1,
         "YES",
         41.0,
         "2025-12-19T14:43:51.956Z"
        ],
        [
         "2000137276",
         "00020",
         "4500234397",
         "00020",
         "9900",
         "9900",
         "9900",
         "9900",
         "ZNPR",
         "Local PO",
         "GH",
         "PR_PO_MATCHED",
         0.32579640768042645,
         0,
         "NO",
         1.0,
         "2025-12-19T14:43:51.956Z"
        ],
        [
         "2000126351",
         "00240",
         "4500229324",
         "00240",
         "9900",
         "9900",
         "9900",
         "9900",
         "ZNPR",
         "Local PO",
         "GH",
         "PR_PO_MATCHED",
         0.9860368550270854,
         1,
         "YES",
         41.0,
         "2025-12-19T14:43:51.956Z"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "pr_purchaserequisition",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "pr_itemnumber",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "purchaseorder",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "po_itemnumber",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "pr_companycode",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "po_companycode",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "pr_plant",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "po_plant",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "pr_documenttype",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "po_purchasingdoctypedesc",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "po_countrykey",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "record_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "pred_sla_breach_probability",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "pred_sla_breach_bin",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "pred_sla_breach_label",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "pred_pr_to_po_ageing",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "scoring_timestamp",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating endpoint: ban6800-procurement-sla-combined\n\n✅ DONE: UC model in GOLD schema + one endpoint + predictions table in GOLD\n   Model    : abc.abc_dw_gold.abc_dw_gd_model_Procurement_sla_Combined_Model_BAN6800 v7\n   Endpoint : ban6800-procurement-sla-combined\n   Pred Tbl : abc.abc_dw_gold.abc_dw_gl_pr_po_kpi_predictions\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# BAN6800 - Data Analytics Capstone\n",
    "# Final Project: End-to-End ML Model Training, Registration, Deployment & Scoring\n",
    "# Project Name – Databricks-Enabled Procurement Analytics Optimization (Train + Register in GOLD + Deploy 1 Endpoint + Score Model + Write Back to GOLD Schema)\n",
    "# Author: Taiwo Babalola\n",
    "# Learner ID: 162894\n",
    "# Submitted to: DR Raphael Wanjiku\n",
    "# =======================================================\n",
    "\n",
    "# =======================================================\n",
    "# Source  : abc.abc_dw_gold.abc_dw_gl_pr_po_kpi\n",
    "# Output Predictiona table  : abc.abc_dw_gold.abc_dw_gl_pr_po_kpi_predictions\n",
    "# Model Registry: Unity Catalog Model Registry -> abc.abc_dw_gold.abc_dw_gd_model_Procurement_Combined_Model_BAN6800\n",
    "# Endpoint: One Databricks Model Serving endpoint (abc.abc_dw_gold.ban6800-procurement-sla-combined)\n",
    "# =======================================================\n",
    "\n",
    "# -----------------------------\n",
    "# 0. INSTALLS (only if needed)\n",
    "# -----------------------------\n",
    "# %pip install -U mlflow databricks-sdk imbalanced-learn scikit-learn\n",
    "# dbutils.library.restartPython()\n",
    "\n",
    "# -----------------------------\n",
    "# 1. IMPORTS\n",
    "# -----------------------------\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import (\n",
    "    ServedEntityInput,\n",
    "    EndpointCoreConfigInput,\n",
    "    TrafficConfig,\n",
    "    Route\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. CONFIG (EDIT THESE)\n",
    "# -----------------------------\n",
    "CATALOG = \"abc\"\n",
    "GOLD_SCHEMA = \"abc_dw_gold\"\n",
    "\n",
    "GOLD_TABLE = f\"{CATALOG}.{GOLD_SCHEMA}.abc_dw_gl_pr_po_kpi\"\n",
    "PRED_TABLE = f\"{CATALOG}.{GOLD_SCHEMA}.abc_dw_gl_pr_po_kpi_predictions\"\n",
    "\n",
    "# ✅ UC Model name (must be 3-level for Unity Catalog)\n",
    "MODEL_NAME = f\"{CATALOG}.{GOLD_SCHEMA}.abc_dw_gd_model_Procurement_sla_Combined_Model_BAN6800\"\n",
    "\n",
    "# ✅ Workspace experiment (can remain workspace path)\n",
    "EXPERIMENT_PATH = \"/Shared/Procurement_SLA_Models\"\n",
    "\n",
    "# Endpoint name (must be unique in workspace)\n",
    "ENDPOINT_NAME = \"ban6800-procurement-sla-combined\"\n",
    "\n",
    "# Serving workload size (common values: \"Small\", \"Medium\", \"Large\")\n",
    "WORKLOAD_SIZE = \"Small\"\n",
    "\n",
    "# Classification threshold\n",
    "SLA_THRESHOLD = 0.55\n",
    "\n",
    "# Optional: only train/score meaningful matched records\n",
    "RECORD_TYPE_FILTER = \"PR_PO_MATCHED\"\n",
    "\n",
    "# -----------------------------\n",
    "# 3. IMPORTANT: USE UC MODEL REGISTRY\n",
    "# -----------------------------\n",
    "# ✅ This is what makes the model “saved on GOLD schema” (Unity Catalog)\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "mlflow.set_experiment(EXPERIMENT_PATH)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. LOAD GOLD DATA (SPARK -> PANDAS)\n",
    "# -----------------------------\n",
    "df_spark = spark.table(GOLD_TABLE)\n",
    "if \"record_type\" in df_spark.columns:\n",
    "    df_spark = df_spark.filter(F.col(\"record_type\") == RECORD_TYPE_FILTER)\n",
    "\n",
    "df_pd = df_spark.toPandas()\n",
    "print(\"Loaded Gold rows:\", df_pd.shape[0], \"cols:\", df_pd.shape[1])\n",
    "\n",
    "# =======================================================\n",
    "# 5. TRAIN SLA CLASSIFIER (SMOTE + RF)\n",
    "# =======================================================\n",
    "clf_df = df_pd[df_pd[\"sla_breach_flag\"].isin([\"YES\", \"NO\"])].copy()\n",
    "clf_df[\"sla_breach_flag_bin\"] = np.where(clf_df[\"sla_breach_flag\"] == \"YES\", 1, 0)\n",
    "\n",
    "# ---- Leak-free numeric/categorical features (ensure stable order!)\n",
    "num_clf = [c for c in [\"pr_orderqty\", \"po_orderquantity\", \"po_netamount\"] if c in clf_df.columns]\n",
    "\n",
    "cat_clf = [c for c in [\n",
    "    \"pr_companycode\",\n",
    "    \"po_purchasingorgdesc\",\n",
    "    \"po_companycode\",\n",
    "    \"po_companycodedesc\",\n",
    "    \"pr_plant\",\n",
    "    \"po_plant\",\n",
    "    \"pr_documenttype\",\n",
    "    \"po_purchasingdoctypedesc\",\n",
    "    \"po_purchasinggroupdesc\",\n",
    "    \"po_countrykey\",\n",
    "    \"materialgroupdesc\",\n",
    "    \"materialtypedesc\",\n",
    "    \"record_type\",\n",
    "] if c in clf_df.columns]\n",
    "\n",
    "# enforce explicit order\n",
    "num_clf = list(num_clf)\n",
    "cat_clf = list(cat_clf)\n",
    "\n",
    "clf_model_df = clf_df[num_clf + cat_clf + [\"sla_breach_flag_bin\"]].copy()\n",
    "clf_model_df[num_clf] = clf_model_df[num_clf].fillna(0)\n",
    "clf_model_df[cat_clf] = clf_model_df[cat_clf].fillna(\"Unknown\")\n",
    "\n",
    "X_clf = clf_model_df[num_clf + cat_clf]\n",
    "y_clf = clf_model_df[\"sla_breach_flag_bin\"]\n",
    "\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X_clf, y_clf, test_size=0.2, random_state=42, stratify=y_clf\n",
    ")\n",
    "\n",
    "preprocessor_clf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_clf),\n",
    "        (\"num\", \"passthrough\", num_clf),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "X_train_enc = preprocessor_clf.fit_transform(X_train_clf)\n",
    "X_test_enc = preprocessor_clf.transform(X_test_clf)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = sm.fit_resample(X_train_enc, y_train_clf)\n",
    "\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=120,\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=10,\n",
    "    class_weight=\"balanced\",\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    bootstrap=True\n",
    ")\n",
    "rf_clf.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "y_proba = rf_clf.predict_proba(X_test_enc)[:, 1]\n",
    "y_pred = (y_proba >= SLA_THRESHOLD).astype(int)\n",
    "\n",
    "sla_metrics = {\n",
    "    \"sla_accuracy\": float(accuracy_score(y_test_clf, y_pred)),\n",
    "    \"sla_precision\": float(precision_score(y_test_clf, y_pred, zero_division=0)),\n",
    "    \"sla_recall\": float(recall_score(y_test_clf, y_pred, zero_division=0)),\n",
    "    \"sla_f1\": float(f1_score(y_test_clf, y_pred, zero_division=0)),\n",
    "    \"sla_auc\": float(roc_auc_score(y_test_clf, y_proba)),\n",
    "    \"sla_threshold\": float(SLA_THRESHOLD),\n",
    "}\n",
    "print(\"SLA metrics:\", sla_metrics)\n",
    "\n",
    "# =======================================================\n",
    "# 6. TRAIN REGRESSOR (RF)\n",
    "# =======================================================\n",
    "if \"pr_to_po_ageing\" not in df_pd.columns:\n",
    "    raise ValueError(\"pr_to_po_ageing column missing in Gold dataset.\")\n",
    "\n",
    "reg_df = df_pd[df_pd[\"pr_to_po_ageing\"].notna()].copy()\n",
    "target_reg = \"pr_to_po_ageing\"\n",
    "\n",
    "num_reg = [c for c in [\n",
    "    \"pr_approval_ageing\",\n",
    "    \"po_approval_ageing\",\n",
    "    \"pr_orderqty\",\n",
    "    \"po_orderquantity\",\n",
    "    \"po_netamount\",\n",
    "] if c in reg_df.columns]\n",
    "\n",
    "cat_reg = [c for c in [\n",
    "    \"pr_companycode\",\n",
    "    \"po_purchasingorgdesc\",\n",
    "    \"po_companycode\",\n",
    "    \"po_companycodedesc\",\n",
    "    \"pr_plant\",\n",
    "    \"po_plant\",\n",
    "    \"pr_documenttype\",\n",
    "    \"po_purchasingdoctype\",\n",
    "    \"po_purchasingdoctypedesc\",\n",
    "    \"po_purchasinggroupdesc\",\n",
    "    \"po_countrykey\",\n",
    "    \"materialgroupdesc\",\n",
    "    \"materialtypedesc\",\n",
    "    \"record_type\",\n",
    "] if c in reg_df.columns]\n",
    "\n",
    "# enforce explicit order\n",
    "num_reg = list(num_reg)\n",
    "cat_reg = list(cat_reg)\n",
    "\n",
    "reg_model_df = reg_df[num_reg + cat_reg + [target_reg]].copy()\n",
    "reg_model_df[num_reg] = reg_model_df[num_reg].fillna(0)\n",
    "reg_model_df[cat_reg] = reg_model_df[cat_reg].fillna(\"Unknown\")\n",
    "\n",
    "X_reg = reg_model_df[num_reg + cat_reg]\n",
    "y_reg = reg_model_df[target_reg]\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "preprocessor_reg = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_reg),\n",
    "        (\"num\", \"passthrough\", num_reg),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "X_train_reg_enc = preprocessor_reg.fit_transform(X_train_reg)\n",
    "X_test_reg_enc = preprocessor_reg.transform(X_test_reg)\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "rf_reg.fit(X_train_reg_enc, y_train_reg)\n",
    "\n",
    "y_pred_reg = rf_reg.predict(X_test_reg_enc)\n",
    "\n",
    "reg_metrics = {\n",
    "    \"reg_mae\": float(mean_absolute_error(y_test_reg, y_pred_reg)),\n",
    "    \"reg_rmse\": float(np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))),\n",
    "    \"reg_r2\": float(r2_score(y_test_reg, y_pred_reg)),\n",
    "}\n",
    "print(\"REG metrics:\", reg_metrics)\n",
    "\n",
    "# =======================================================\n",
    "# 7. ONE PYFUNC MODEL (COMBINED) FOR ONE ENDPOINT\n",
    "# =======================================================\n",
    "class ProcurementCombinedModel(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, pre_clf, clf, threshold, num_clf, cat_clf, pre_reg, reg, num_reg, cat_reg):\n",
    "        self.pre_clf = pre_clf\n",
    "        self.clf = clf\n",
    "        self.threshold = float(threshold)\n",
    "        self.num_clf = list(num_clf)\n",
    "        self.cat_clf = list(cat_clf)\n",
    "        self.pre_reg = pre_reg\n",
    "        self.reg = reg\n",
    "        self.num_reg = list(num_reg)\n",
    "        self.cat_reg = list(cat_reg)\n",
    "\n",
    "        # store strict column orders (prevents the “feature names should match/order” error)\n",
    "        self._clf_cols = self.num_clf + self.cat_clf\n",
    "        self._reg_cols = self.num_reg + self.cat_reg\n",
    "\n",
    "    def predict(self, context, model_input: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_in = model_input.copy()\n",
    "\n",
    "        # --- SLA inputs (strict order)\n",
    "        Xc = df_in.reindex(columns=self._clf_cols, fill_value=np.nan).copy()\n",
    "        if self.num_clf:\n",
    "            Xc[self.num_clf] = Xc[self.num_clf].fillna(0)\n",
    "        if self.cat_clf:\n",
    "            Xc[self.cat_clf] = Xc[self.cat_clf].fillna(\"Unknown\")\n",
    "        Xc_enc = self.pre_clf.transform(Xc)\n",
    "        proba = self.clf.predict_proba(Xc_enc)[:, 1]\n",
    "        pred_bin = (proba >= self.threshold).astype(int)\n",
    "        pred_lbl = np.where(pred_bin == 1, \"YES\", \"NO\")\n",
    "\n",
    "        # --- REG inputs (strict order)\n",
    "        Xr = df_in.reindex(columns=self._reg_cols, fill_value=np.nan).copy()\n",
    "        if self.num_reg:\n",
    "            Xr[self.num_reg] = Xr[self.num_reg].fillna(0)\n",
    "        if self.cat_reg:\n",
    "            Xr[self.cat_reg] = Xr[self.cat_reg].fillna(\"Unknown\")\n",
    "        Xr_enc = self.pre_reg.transform(Xr)\n",
    "        pred_days = self.reg.predict(Xr_enc)\n",
    "\n",
    "        return pd.DataFrame({\n",
    "            \"pred_sla_breach_probability\": proba,\n",
    "            \"pred_sla_breach_bin\": pred_bin,\n",
    "            \"pred_sla_breach_label\": pred_lbl,\n",
    "            \"pred_pr_to_po_ageing\": pred_days\n",
    "        })\n",
    "\n",
    "pyfunc_model = ProcurementCombinedModel(\n",
    "    pre_clf=preprocessor_clf,\n",
    "    clf=rf_clf,\n",
    "    threshold=SLA_THRESHOLD,\n",
    "    num_clf=num_clf,\n",
    "    cat_clf=cat_clf,\n",
    "    pre_reg=preprocessor_reg,\n",
    "    reg=rf_reg,\n",
    "    num_reg=num_reg,\n",
    "    cat_reg=cat_reg\n",
    ")\n",
    "\n",
    "# =======================================================\n",
    "# 8. LOG + REGISTER MODEL INTO UC GOLD SCHEMA\n",
    "# =======================================================\n",
    "mlflow.end_run()\n",
    "\n",
    "# Build a valid input example that contains ALL required columns (union)\n",
    "all_cols_union = []\n",
    "for c in (num_clf + cat_clf + num_reg + cat_reg):\n",
    "    if c not in all_cols_union:\n",
    "        all_cols_union.append(c)\n",
    "\n",
    "input_example = df_pd.reindex(columns=all_cols_union).head(5).copy()\n",
    "sample_out = pyfunc_model.predict(None, input_example)\n",
    "signature = infer_signature(input_example, sample_out)\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "with mlflow.start_run(run_name=\"BAN6800_UC_Combined_Model\") as run:\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    mlflow.log_metrics({**sla_metrics, **reg_metrics})\n",
    "    mlflow.log_params({\n",
    "        \"gold_table\": GOLD_TABLE,\n",
    "        \"record_type_filter\": RECORD_TYPE_FILTER,\n",
    "        \"sla_threshold\": SLA_THRESHOLD,\n",
    "        \"clf_estimators\": 120,\n",
    "        \"clf_max_depth\": 5,\n",
    "        \"reg_estimators\": 200,\n",
    "    })\n",
    "\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=pyfunc_model,\n",
    "        signature=signature,\n",
    "        input_example=input_example\n",
    "    )\n",
    "\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "    # Create registered model in UC if missing\n",
    "    try:\n",
    "        _ = client.get_registered_model(MODEL_NAME)\n",
    "    except Exception:\n",
    "        # If it doesn't exist, try creating it\n",
    "        try:\n",
    "            client.create_registered_model(MODEL_NAME)\n",
    "        except Exception:\n",
    "            # register_model can still create in many cases; ignore if already exists or auto-creates\n",
    "            pass\n",
    "\n",
    "    reg = mlflow.register_model(model_uri, MODEL_NAME)\n",
    "    model_version = str(reg.version)\n",
    "\n",
    "print(f\"✅ UC Model registered: {MODEL_NAME} v{model_version}\")\n",
    "\n",
    "# =======================================================\n",
    "# 9. SCORE FULL GOLD + WRITE BACK TO GOLD SCHEMA\n",
    "# =======================================================\n",
    "score_in = df_pd.reindex(columns=all_cols_union).copy()\n",
    "pred_pd = pyfunc_model.predict(None, score_in)\n",
    "pred_pd[\"scoring_timestamp\"] = pd.Timestamp.utcnow()\n",
    "\n",
    "# Keep some identifiers if present\n",
    "id_cols = [c for c in [\n",
    "    \"pr_purchaserequisition\", \"pr_itemnumber\",\n",
    "    \"purchaseorder\", \"po_itemnumber\",\n",
    "    \"pr_companycode\", \"po_companycode\",\n",
    "    \"pr_plant\", \"po_plant\",\n",
    "    \"pr_documenttype\", \"po_purchasingdoctypedesc\",\n",
    "    \"po_countrykey\", \"record_type\"\n",
    "] if c in df_pd.columns]\n",
    "\n",
    "out_pd = df_pd[id_cols].copy() if id_cols else pd.DataFrame(index=df_pd.index)\n",
    "out_pd = pd.concat([out_pd.reset_index(drop=True), pred_pd.reset_index(drop=True)], axis=1)\n",
    "\n",
    "pred_spark = spark.createDataFrame(out_pd)\n",
    "\n",
    "(\n",
    "    pred_spark.write.format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(PRED_TABLE)\n",
    ")\n",
    "print(f\"✅ Predictions written to: {PRED_TABLE}\")\n",
    "display(spark.table(PRED_TABLE).limit(10))\n",
    "\n",
    "# =======================================================\n",
    "# 10. DEPLOY/UPSERT ONE MODEL SERVING ENDPOINT\n",
    "# =======================================================\n",
    "#%python\n",
    "def upsert_endpoint(endpoint_name: str, model_name: str, model_version: str):\n",
    "    w = WorkspaceClient()\n",
    "\n",
    "    served_entity_name = f\"procurement-combined-{model_version}\"  # must match route\n",
    "\n",
    "    served = ServedEntityInput(\n",
    "        name=served_entity_name,\n",
    "        entity_name=model_name,            # UC model name: abc.abc_dw_gold.<model>\n",
    "        entity_version=str(model_version),\n",
    "        workload_size=WORKLOAD_SIZE,\n",
    "        scale_to_zero_enabled=True\n",
    "    )\n",
    "\n",
    "    core_cfg = EndpointCoreConfigInput(\n",
    "        served_entities=[served],\n",
    "        traffic_config=TrafficConfig(\n",
    "            routes=[Route(served_model_name=served_entity_name, traffic_percentage=100)]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        w.serving_endpoints.get(name=endpoint_name)\n",
    "        print(f\"Updating endpoint: {endpoint_name}\")\n",
    "        w.serving_endpoints.update_config(\n",
    "            name=endpoint_name,\n",
    "            served_entities=core_cfg.served_entities,\n",
    "            traffic_config=core_cfg.traffic_config\n",
    "        )\n",
    "    except Exception:\n",
    "        print(f\"Creating endpoint: {endpoint_name}\")\n",
    "        w.serving_endpoints.create(name=endpoint_name, config=core_cfg)\n",
    "\n",
    "#    print(f\"✅ Endpoint upsert submitted: {endpoint_name}\")\n",
    "upsert_endpoint(ENDPOINT_NAME, MODEL_NAME, model_version)\n",
    "\n",
    "print(\"\\n✅ DONE: UC model in GOLD schema + one endpoint + predictions table in GOLD\")\n",
    "print(f\"   Model    : {MODEL_NAME} v{model_version}\")\n",
    "print(f\"   Endpoint : {ENDPOINT_NAME}\")\n",
    "print(f\"   Pred Tbl : {PRED_TABLE}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "BAN6800_Final_Project_Procurement_Model_and_endpoint",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}